{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Simple RNN TF1\n",
    "\n",
    "** This is the implementation for TensorFlow 1.0 and python 3.4. It uses the TF-RNN library for training.** For another more manual implementation see simple_rnn.\n",
    "\n",
    "In this notebook we consider a simple example of an RNN and used a quite artifical data generating process (if you have a better idea / story please contact me). \n",
    "\n",
    "The example has been motivated by:\n",
    "http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html. \n",
    "\n",
    "Other Resources for RNNs:\n",
    "\n",
    "* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/\n",
    "* http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html\n",
    "* http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* http://www.deeplearningbook.org/contents/rnn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.0',\n",
       " sys.version_info(major=3, minor=4, micro=3, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from six.moves.cPickle import loads\n",
    "import numpy as np\n",
    "import sys\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__, sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Global config variables (see below)\n",
    "num_steps = 40     # number of truncated backprop steps\n",
    "batch_size = 200  # number of minibatches b\n",
    "num_classes_in = 3   # number of classes in the input\n",
    "num_classes_out = 2   # number of classes in the output\n",
    "state_size = 4    # number of classes in the state\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Helper functions\n",
    "def one_hot(Y, max):\n",
    "    d = np.zeros((len(Y),max), dtype='int32')\n",
    "    for row,col in enumerate(Y):\n",
    "        d[row, col] = 1\n",
    "    return d    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Definition of the task\n",
    "\n",
    "We consider a network which predicts at each point in time a variable $\\hat{y}_t$ based on earlier values of $\\hat{y}_{t'}$ covariates $x_t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Example data  (I screama, you screama, we all screama for I screama)\n",
    "\n",
    "We need some data to play around with RNNs. They are capable of doing quite complicated things such as language models and so on. For this example, we want to generate the data ourself. We have to come up with a process which creates $x_t$ which itself can be influcenced by events $x_{t'}$ which happend before $t$. Further, we have to come up with $y_t$ which depends on $x_t'$ for timepoints $t' \\le t$. \n",
    "\n",
    "To keep it simple, we analyse the following quite artifical process in which the weather $x_{t'}$ for $t' \\le t$ influences our stock on icecream $y_t$. We then see if the RNN is capable of reconstructing that process.\n",
    "\n",
    "#### Definition of the simple process\n",
    "The weather $x_t$ at a certain point in time $t$ has three states (sunny, rainy, cloudy), which we model as $x_t = (1,0,0)$, $x_t = (0,1,0)$, and $x_t = (0,0,1)$ repectively. We assume that the weather is completly random (of course we could model more complex scenarios). \n",
    "\n",
    "We have an icecream store capable of holding 2 units of icecream and we start with a full store. When it is sunny we sell one unit of icecream. We have the strange policy that we order  on unit of icecream when it's cloudy. It takes 3 days to deliever the ice cream, we accept the ice cream if we do not have a full stock.\n",
    "\n",
    "This enables us to model $y_t$ the state of the store $(1,0)$ for out of stock and $(0,1)$ for in stock. We create the one-hot-encoded data in the graph later. For now we use integers but keep in mind that the data is categorical. \n",
    "\n",
    "** The important part is that, we have values $y_t$ which can be prediced from earlier** $x_t$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    Xs = np.array(np.random.choice(3, size=(size,))) #Random Weather\n",
    "    Y = []\n",
    "    ice = 2 #Our stock of icecream at start\n",
    "    for t,x in enumerate(Xs):\n",
    "        # (t-3) >= 0 the first ice cream could be delivered on day 3\n",
    "        # Xs[t - 3] claudy three days before today => we ordered ice cream\n",
    "        # ice < 2 not full\n",
    "        if (t - 3) >= 0 and Xs[t - 3] == 1 and ice < 2: \n",
    "            ice += 1\n",
    "        if x == 0: # It is sunny we therefore sell ice, if we have\n",
    "            if ice > 0: # We have ice cream\n",
    "                ice -= 1\n",
    "        if ice > 0: #We are not out of stock\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(0)\n",
    "    return Xs, np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 0, 2, 2, 0, 0, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 0, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2,\n",
       "        1, 0, 1, 1]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = gen_data(50000) #Global variables holding the input and output\n",
    "(X_train[0:50], Y_train[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Forward pass in numpy\n",
    "To better illustrate the used method, we first do a forward-pass of the RNN using numpy. We load the weights which we calculated previously with the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W_, b_, V_, bv_ = np.load('rnn_weights_tf1.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Architecture of the network \n",
    "We now define the network, we do not consider the output nodes yet.\n",
    "A single RNN cell is shown in the figure below in the middle:\n",
    "\n",
    "![](http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png)\n",
    "Image taken from: [Colah's RNN Blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "The joining of the two lines coming from the previous state $h_{t-1}$ and the current x-values $x_t$ is a concantination to a vector  $[h_{t-1}, x_{t}]$ of size `state_size + num_classes_in`. Alternatively, instead of concatinating, one could also use two matrices $W_x$ and $W_h$ and keep the states seperate. This is mathematically completely identical. The new state $h_t$ is then calculated as:\n",
    "\n",
    "$$\n",
    "    h_{t} = \\tanh([h_{t-1}, x_{t}] \\cdot W + b) = \\tanh(h_{t-1} \\cdot W_h + x_{t} \\cdot U + b)\n",
    "$$\n",
    "\n",
    "The dynamic of the hidden state $h_{t}$ is determined by $W$ (and $b$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.19342743,  1.20125043,  0.03041052, -0.7982803 ],\n",
       "        [-1.17504787, -0.35316652,  0.68581891,  1.42157817],\n",
       "        [-0.18561231, -0.16853848,  0.71172661, -0.50630069],\n",
       "        [ 1.03420258,  0.59627861, -0.9009819 ,  0.35502589],\n",
       "        [-0.15730815,  1.02999747, -0.86277425, -0.35499594],\n",
       "        [ 0.16915447, -1.24952602,  0.11196493,  0.41059464],\n",
       "        [-1.52237487,  0.30463067, -1.88313866, -1.14694726]], dtype=float32),\n",
       " array([ 0.12549509,  0.29770762,  0.21737964, -0.32890254], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_, b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.] ---> [-0.0600449   0.12845552  0.73017693 -0.68326001]\n"
     ]
    }
   ],
   "source": [
    "# The first state\n",
    "h0 = np.zeros(state_size) #We start with 0 initial state\n",
    "x1 = one_hot(X_train, num_classes_in)[0] #Make a vector\n",
    "\n",
    "#<---- your code here (calculate the hidden state h1) ---->\n",
    "h1 = np.tanh(np.matmul(np.concatenate([x1, h0]), W_) + b_)\n",
    "#<---- end your code here ---->\n",
    "\n",
    "print(h0, \"--->\", h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We could repeat those transitions of the hidden states to get a sequence of hidden states:\n",
    "\n",
    "$h_0 \\rightarrow h_1 \\rightarrow h_2 \\rightarrow h_3 \\rightarrow h_4 \\ldots $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rnn_forward(state, X_train):\n",
    "    hs = []\n",
    "    for t in range(len(X_train)):\n",
    "        # Note that TF concatenates [Input, State]\n",
    "        state = np.tanh(np.matmul(np.concatenate([X_train[t,:],state]), W_) + b_)\n",
    "        hs.append(state)\n",
    "    return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.0600449 ,  0.12845552,  0.73017693, -0.68326001]),\n",
       " array([ 0.76718624,  0.44218723,  0.91533763, -0.11018243]),\n",
       " array([ 0.75578944, -0.13440726,  0.16483438, -0.21423011]),\n",
       " array([ 0.79930566,  0.16854152,  0.65613562, -0.20291764]),\n",
       " array([ 0.81844978,  0.85311612, -0.16078928, -0.38088856])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_forward(h0, one_hot(X_train[0:5],num_classes_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We add some output. For each time step the output is produced by multiplying the hidden state with:\n",
    "\n",
    "$o_t = h_t \\cdot V + b_{\\tt{v}}$\n",
    "\n",
    "This is a logit, the final the probability of output class is the softmax of the logit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.1591476,  0.545742 ]), array([ 0.33072903,  0.66927097]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<---- your code here (calculate the output state o1 for timestep 1 from h1, V_ and the bias bv_) ---->\n",
    "o1 = np.matmul(h1, V_) + bv_\n",
    "#<---- your code here (calculate probability from the state o1) ---->\n",
    "prob_1 = np.exp(o1)/np.sum(np.exp(o1))\n",
    "#<---- end your code here  ---->\n",
    "o1, prob_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "h = rnn_forward(h0, one_hot(X_train,3))\n",
    "pt = []\n",
    "for t in range(len(h)):\n",
    "    ot = np.matmul(h[t], V_) + bv_\n",
    "    pt.append(np.exp(ot)/np.sum(np.exp(ot)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 0.33072903,  0.66927097]),\n",
       "  array([ 0.75566483,  0.24433517]),\n",
       "  array([ 0.15560883,  0.84439117]),\n",
       "  array([ 0.42810145,  0.57189855]),\n",
       "  array([ 0.97741564,  0.02258436]),\n",
       "  array([ 0.98956735,  0.01043265]),\n",
       "  array([ 0.9835644,  0.0164356]),\n",
       "  array([ 0.97277593,  0.02722407]),\n",
       "  array([ 0.98552958,  0.01447042]),\n",
       "  array([ 0.96432936,  0.03567064])],\n",
       " array([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1]),\n",
       " array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt[0:10], np.argmax(pt[0:30],axis=1), Y_train[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98758000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.argmax(pt, axis=1) == Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tot_loss = 0\n",
    "for i in range(len(Y_train)):\n",
    "    tot_loss += -np.log(pt[i][Y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.060004378195400249"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_loss / len(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training in TensorFlow\n",
    "### Preparation of the Minibatch\n",
    "\n",
    "In this example, we have in principle a large stream of data $x$ and $y$. For efficiency reason we split the stream in minibatches of a certain length. For this task we could also imagin to have several realizations of that icecream process, so that it would also be natural to split the process into mini batches. \n",
    "\n",
    "For simplicyty we create the minibatch by we randomly cutting out `batch_size` entries of fixed length `num_steps`. Other, more advanced ways of doing so are possible. See e.g. https://danijar.com/variable-sequence-lengths-in-tensorflow/. For the time being, we thus consider the input tensor $X_{btc}$ for the minibatch to be of the following form:\n",
    "\n",
    "* $b$ having `batch_size` entries\n",
    "* $t$ loops over the unrolled timestamps (`num_steps`)\n",
    "* $c$ has the dimension of the one-hot-coded classes (the one-hot-encoding will be done in the graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_batch(Xs, Ys, batch_size = 32, num_steps = 50):\n",
    "    data_x = np.zeros([batch_size, num_steps], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, num_steps], dtype=np.int32)\n",
    "    for i in range(1,batch_size):\n",
    "        s = int(np.random.uniform(0, len(Xs) - num_steps))\n",
    "        data_x[i] = Xs[s : s + num_steps]\n",
    "        data_y[i] = Ys[s : s + num_steps]  \n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 2 2 2 2 1 1 1 1]\n",
      " [1 0 0 1 2 1 0 1 0 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [1 0 0 1 1 1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_batch(X_train, Y_train, batch_size=3, num_steps=10)\n",
    "print (X)\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Using the TensorFlow API\n",
    "\n",
    "Alternatively one can use the TensorFlow-API for creating RNNs. In principle there are two TensorFlow methods. The first, kind of deprecated one, builds a graph from the unrolled network. This API has issues in performance, first of all the creation of the graph takes quite some time. Further, and this is a bit it is also slower during runtime. Therefore, the novel dynamic API should be prefered. If you want to use sequences of variable length see:  https://danijar.com/variable-sequence-lengths-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose:0' shape=(200, 40, 3) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(42)\n",
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "# RNN Inputs\n",
    "# One hot encoding.\n",
    "x_one_hot = tf.one_hot(x, num_classes_in)\n",
    "# We want the following dimensions [batch_size, Max_Length, num_classes_in]\n",
    "rnn_inputs = tf.transpose(x_one_hot, perm=(0,1,2))\n",
    "rnn_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the basic cell\n",
    "\n",
    "We have to define the elementary cell, which has a state of a given size. As above we use the basic RNN-Cell which is described in: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#cell = tf.nn.rnn_cell.BasicRNNCell(state_size) \n",
    "#cell = tf.nn.rnn_cell.BasicLSTMCell(state_size)\n",
    "# For tf1.0 the cells have been temporarily moved to a contib see: https://github.com/tensorflow/models/issues/919\n",
    "cell = tf.contrib.rnn.BasicRNNCell(state_size)\n",
    "init_state = cell.zero_state(batch_size, tf.float32)\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/transpose:0' shape=(200, 40, 4) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The output $o_{btk}$ tensor produces for each minibatch and timepoint a 4 (number of output states) dimensional vector indexed by $k$. For each timepoint and batch, we later want to compare this with the corresponding y-value with has the shape $y_{bt}$. In a first step we flatten the b and t dimension to a $200*40 = 8000$ dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Reshape_1:0' shape=(8000,) dtype=int32>,\n",
       " <tf.Tensor 'Reshape:0' shape=(8000, 4) dtype=float32>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshape rnn_outputs and y so we can get the logits in a single matmul\n",
    "rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "y_reshaped = tf.reshape(y, [-1])\n",
    "y_reshaped, rnn_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'add:0' shape=(8000, 2) dtype=float32>,\n",
       " <tf.Tensor 'Reshape_1:0' shape=(8000,) dtype=int32>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.variable_scope('softmax'):\n",
    "    V = tf.get_variable('V', [state_size, num_classes_out])\n",
    "    bv = tf.get_variable('bv', [num_classes_out], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "logits = tf.matmul(rnn_outputs, V) + bv\n",
    "logits, y_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#writer = tf.summary.FileWriter(\"tb_simple_rnn_tf1/dd\", tf.get_default_graph()) \n",
    "#writer.close()\n",
    "#!tensorboard --logdir=tb_simple_rnn_tf1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_reshaped, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-123b9d588c03>:7: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "0 0.6831499338150024\n",
      "1 0.6532474160194397\n",
      "2 0.640494704246521\n",
      "3 0.6144058704376221\n",
      "4 0.5690740942955017\n",
      "5 0.6485346555709839\n",
      "6 0.5548587441444397\n",
      "7 0.5476928949356079\n",
      "8 0.5383784174919128\n",
      "9 0.5115993022918701\n",
      "200 0.2237984576306418\n",
      "400 0.18446169406175614\n",
      "600 0.17015162907540798\n",
      "800 0.16602394267916679\n"
     ]
    }
   ],
   "source": [
    "Y = None\n",
    "X = None\n",
    "count = 0\n",
    "sum_tr_losses = 0\n",
    "sess = tf.Session()\n",
    "#with tf.Session() as sess:\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "    X, Y = get_batch(X_train, Y_train, batch_size, num_steps)\n",
    "    tr_losses, _ = sess.run([total_loss, train_step], feed_dict={x:X, y:Y})\n",
    "    count += 1\n",
    "    sum_tr_losses += tr_losses\n",
    "    if (i < 10) or (i % 200 == 0):\n",
    "        print (\"{} {}\".format(i, sum_tr_losses / count))\n",
    "        count = 0\n",
    "        sum_tr_losses = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15341146"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = get_batch(X_train, Y_train, batch_size, num_steps)\n",
    "loss_train = sess.run(total_loss, feed_dict={x:X, y:Y})\n",
    "loss_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the relevant weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finding the relavant weights\n",
    "#ops = tf.get_default_graph().get_operations()\n",
    "#for i in ops:\n",
    "#   print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19342743  1.20125043  0.03041052 -0.7982803 ]\n",
      " [-1.17504787 -0.35316652  0.68581891  1.42157817]\n",
      " [-0.18561231 -0.16853848  0.71172661 -0.50630069]\n",
      " [ 1.03420258  0.59627861 -0.9009819   0.35502589]\n",
      " [-0.15730815  1.02999747 -0.86277425 -0.35499594]\n",
      " [ 0.16915447 -1.24952602  0.11196493  0.41059464]\n",
      " [-1.52237487  0.30463067 -1.88313866 -1.14694726]] [ 0.12549509  0.29770762  0.21737964 -0.32890254] [[-0.08837788  0.04871782]\n",
      " [ 2.23107862 -3.23202324]\n",
      " [-0.11032624  0.4064675 ]\n",
      " [ 0.07012325 -0.50414103]] [-0.32257852  0.32258588]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "W = graph.get_tensor_by_name('rnn/basic_rnn_cell/weights:0')\n",
    "b = graph.get_tensor_by_name('rnn/basic_rnn_cell/biases:0')\n",
    "W_,b_,V_,bv_ = sess.run([W,b,V,bv])\n",
    "print (W_,b_,V_,bv_)\n",
    "np.save('rnn_weights_tf1', [W_,b_,V_,bv_])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
