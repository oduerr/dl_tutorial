{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Example of a pretrained RNN character model. \n",
    "\n",
    "This example show a pre-trained RNN making predictions. \n",
    "\n",
    "#### Data and preprocessing\n",
    "The text for training has been extracted for the Phd thesis:\n",
    "\n",
    "Joller-Graf, Klaus, Herrn Prof Dr Wilfried Schley, and Frau Prof Dr Ingeborg Kriwet. \"Didaktik des integrativen Unterrichts.\"\n",
    "\n",
    "Which can be downloaded from: http://edudoc.ch/record/3408/files/zu05056.pdf\n",
    "\n",
    "Creating the text-file from the pdf via:\n",
    "```\n",
    "    ~/Downloads/xpdfbin-mac-3.04/bin64/pdftotext  -enc UTF-8 zu05056.pdf\n",
    "```\n",
    "http://stackoverflow.com/questions/4039930/how-to-save-text-file-in-utf-8-format-using-pdftotext\n",
    "\n",
    "This text has been preprocessed with \n",
    "```\n",
    "X, Y, char_idx = \\\n",
    "    textfile_to_semi_redundant_sequences(path, seq_maxlen=maxlen, redun_step=3)\n",
    "```\n",
    "yielding\n",
    "```\n",
    "Text total length: 1418267\n",
    "Distinct chars: 109\n",
    "Total sequences: 472748\n",
    "```\n",
    "\n",
    "### The network\n",
    "Here we use the trained network, which we obtained using the library tflearn, as follows:\n",
    "\n",
    "#### Definition\n",
    "The network has been defined in tflearn as:\n",
    "```\n",
    "g = tflearn.input_data([None, maxlen, len(char_idx)])\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512, return_seq=True)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.lstm(g, 512)\n",
    "g = tflearn.dropout(g, 0.5)\n",
    "g = tflearn.fully_connected(g, len(char_idx), activation='softmax')\n",
    "g = tflearn.regression(g, optimizer='ADAM', loss='categorical_crossentropy',\n",
    "                       learning_rate=0.001)\n",
    "\n",
    "m = tflearn.SequenceGenerator(g, dictionary=char_idx,\n",
    "                              seq_maxlen=maxlen,\n",
    "                              clip_gradients=5.0,\n",
    "                              checkpoint_path='model_shakespeare')\n",
    "```\n",
    "Note that the network guesses the next letter using all, the hidden states of all neurons of the last layer. \n",
    "\n",
    "#### Training\n",
    "...and fitted (50 epochs) using:\n",
    "```\n",
    "for i in range(50):\n",
    "        seed = random_sequence_from_textfile(path, maxlen)\n",
    "        m.fit(X, Y, validation_set=0.1, batch_size=128,\n",
    "              n_epoch=1, run_id='shakespeare')\n",
    "        print(\"-- TESTING...\")\n",
    "        print(\"-- Test with temperature of 1.0 --\")\n",
    "        print(m.generate(600, temperature=1.0, seq_seed=seed))\n",
    "        print(\"-- Test with temperature of 0.5 --\")\n",
    "        print(m.generate(600, temperature=0.5, seq_seed=seed))    \n",
    "```\n",
    "\n",
    "#### Freezing\n",
    "finally the model has been frozen with:\n",
    "```\n",
    "# Loading the pretrained model from the checkpoint\n",
    "m.load('/home/dueo/Dropbox/__ZHAW/Projekte/RNN/model_shakespeare-166250')\n",
    "sess = m.session\n",
    "graph = tf.get_default_graph()\n",
    "input_graph_def = graph.as_graph_def()\n",
    "from tensorflow.python.framework import graph_util\n",
    "# The output node names are used to determine which \n",
    "# part of the graph needs to be frozen.\n",
    "output_node_names = \"FullyConnected/Softmax\"\n",
    "output_graph_def = graph_util.convert_variables_to_constants(\n",
    "        sess, # The session is used to retrieve the weights\n",
    "        input_graph_def, # The graph_def is used to retrieve the nodes\n",
    "        output_node_names.split(\",\") \n",
    "    )\n",
    "\n",
    "with tf.gfile.GFile('didactic_25.pb', \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The network .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "maxlen = 25 #The maximal lenth of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'F', 'e', 'I', ',', 'a', 'r', ' ', '[', '©'],\n",
       " [15, 67, 103, 95, 5, 101, 77, 3, 45, 59])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import gzip\n",
    "\n",
    "with open('zu05056_char_idx.pkl', 'rb') as f:\n",
    "    if sys.version_info.major > 2:\n",
    "        char_idx = pickle.load(f, encoding='latin1')\n",
    "    else:\n",
    "        char_idx = pickle.load(f)\n",
    "        \n",
    "list(char_idx.keys())[20:30],list(char_idx.values())[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Downloading of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 22M Jan  9 10:01 didactic_25.pb\r\n"
     ]
    }
   ],
   "source": [
    "# Downloading the model, if it does not exist\n",
    "import urllib\n",
    "import os\n",
    "if not os.path.isfile('didactic_25.pb'):\n",
    "    urllib.urlretrieve(\"https://dl.dropboxusercontent.com/u/9154523/models/rnn_fun/didactic_25.pb\", \"didactic_25.pb\")\n",
    "%ls -hl didactic_25.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.gfile.GFile('didactic_25.pb', \"rb\") as f:\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph().as_default() \n",
    "tf.import_graph_def(graph_def,  name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ops = tf.get_default_graph().get_operations()\n",
    "#for i in ops:print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()\n",
    "feed = graph.get_tensor_by_name('InputData/X:0')\n",
    "fetch = graph.get_tensor_by_name('FullyConnected/Softmax:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Die Grundlagen war dabei ', 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The seed for prediction. Note that the seed need to be exactely of length maxlen\n",
    "seed = 'Die Grundlagen war dabei '[0:maxlen]\n",
    "seed, len(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a one-hot-encoded matrix\n",
    "X = np.zeros((1, maxlen, len(char_idx))) #One Batch, t, X_t (one-got-encoded)\n",
    "for t, char in enumerate(seed):\n",
    "    X[0, t, char_idx[char]] = 1.0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    pred = sess.run(fetch, feed_dict={feed:X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nl = np.argmax(pred) #next letter\n",
    "nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code taken from from tflearn\n",
    "def reverse_dictionary(char_idx):\n",
    "    # Build reverse dict\n",
    "    rev_dic = {}\n",
    "    for key in char_idx:\n",
    "        rev_dic[char_idx[key]] = key\n",
    "    return rev_dic\n",
    "\n",
    "rev_dic = reverse_dictionary(char_idx)\n",
    "rev_dic[nl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 'd')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _sample(a, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    logit = np.log(a) \n",
    "    p = np.exp(logit / temperature)\n",
    "    #1.001 to be on the save side, sum(p) < 1 for np.random.multinomial\n",
    "    p /= (1.001 * np.sum(p))\n",
    "    return np.argmax(np.random.multinomial(1, p, 1))\n",
    "\n",
    "n = _sample(pred[0])\n",
    "n, rev_dic[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "das Er"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fahrungsigen: In: A. Eberwein, SchÃ¼ler (Handollal, E. & Schley, B. & Heuten 1997) arbeitet â auf Wahrnehmung in der Sachkompetenz der SchÃ¼ler (hier um das Verhalten gehalten wurde. Die MÃ¶glichkeit finden ypielen Troten gehen und ausreichend die Gruppenvermittlung und Lehrerin dyraus wieder als Arbeiten. Diese Verleding mit Schulkompetenz - eine Methoden auf die Fertigkeiten, die einer b\n",
      "\n",
      "Die Grundlagen war dabei das Erfahrungsigen: In: A. Eberwein, SchÃ¼ler (Handollal, E. & Schley, B. & Heuten 1997) arbeitet â auf Wahrnehmung in der Sachkompetenz der SchÃ¼ler (hier um das Verhalten gehalten wurde. Die MÃ¶glichkeit finden ypielen Troten gehen und ausreichend die Gruppenvermittlung und Lehrerin dyraus wieder als Arbeiten. Diese Verleding mit Schulkompetenz - eine Methoden auf die Fertigkeiten, die einer b\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# Code adapted from tflearn SequenceGenerator\n",
    "def generate(sess, seq_seed, show=True, seq_length = 400, temperature = 0.1,  seq_maxlen=25):\n",
    "    sequence = seq_seed\n",
    "    generated = seq_seed\n",
    "    dic = char_idx\n",
    "    rev_dic = reverse_dictionary(dic)\n",
    "\n",
    "\n",
    "    whole_sequence = seq_seed\n",
    "\n",
    "    for i in range(seq_length):\n",
    "        X = np.zeros((1, seq_maxlen, len(dic)))\n",
    "        for t, char in enumerate(sequence):\n",
    "            X[0, t, dic[char]] = 1.\n",
    "        preds = sess.run(fetch, feed_dict={feed:X})[0] #Getting next letter distribution\n",
    "        next_index = _sample(preds, temperature) #Sampling a letter from the distribution\n",
    "        #next_index = np.argmax(preds)\n",
    "        next_char = rev_dic[next_index]\n",
    "        if show:\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        generated += next_char\n",
    "        sequence = sequence[1:] + next_char\n",
    "        whole_sequence += next_char\n",
    "    return whole_sequence\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    res = generate(sess, seed, temperature=1.0)\n",
    "    print('\\n')\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Some further examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Temperature 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Grundlagen war dabei diskutiert. Da nicht mit dem Achten zusammeny Anspruch durch persÃ¶nliche Arbeit entgegenser Pinge und insgesamt nehmen Didaktik stÃ¼rzen. Abgeschlossen, dass sie nicht sehr stark aufgebauten, die bise, dass Bereitschaftsbereichen Texter zu kommen ist eine zu kritische Prinzipien zu erkennen und in dieser Grundlage, gibt. NatÃ¼rlich kann in diesem Anspruch, das Probleme vor, die Portfellen im etwa\n",
      "\n",
      "Temperature 1.0\n",
      "Die Grundlagen war dabei dem Phase entscheiden. Ich dem Wohlung des zusammengesetzt die Ergebnisse nach dem Menschen ihrer Entscheide gegrafiert werden, die sie zu eigenen Fragen gebenâ (Bianca L./MS1).\n",
      "âUnd mit weisenden heisst, erste LernmÃ¶glichkeiten erkennen. In seiner Kleinigen ist ein frei zu werden fest, dass die Kinder wird die integrierten SchÃ¼lerinnen und SchÃ¼ler. âJe nach dem Lehren und Fertigkeiten nÃ\n",
      "\n",
      "Temperature 0.5\n",
      "Die Grundlagen war dabei die SchÃ¼lerinnen und SchÃ¼ler auf den Punkt in der Schule erwÃ¤hnt wird. Die eine Klasse im Gegensatz auf eine Planung der SchÃ¼lerinnen und SchÃ¼ler in der Beurteilung und Konflikte mit der Gruppe ist die Kinder bestimmte VerstÃ¤ndnis dieser Arbeit ist ein ganz zentrales Problemen der Lehrpersonen die anderen Kompetenzen zu bestimmen kann. Das mÃ¼ssen wir mÃ¼ssen das so ansetzen die SchÃ¼lerinne\n",
      "\n",
      "Temperature 0.5\n",
      "Die Grundlagen war dabei die SchÃ¼lerinnen und SchÃ¼lern die Lehrpersonen gewisse Arten zu erhÃ¶hen, die diese Probleme der Aussage und in der Auseinandersetzung mit dem den Motivation auf den SchÃ¼lerinnen und SchÃ¼ler in der Gesellschaft der SchÃ¼ler und Fertigkeiten von Prozess der Kinder und Jugendlichen Ã¼ber die SchÃ¼lerinnen und SchÃ¼lern zum Unterricht als in der Material an, die Didaktik mehr Probleme an die Lehr\n",
      "\n",
      "Temperature 0.1\n",
      "Die Grundlagen war dabei die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist auch die SchÃ¼lerinnen und SchÃ¼ler sehr stark die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist auch die Lehrperson die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist auch die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist auch die Lehrperson die Lehrpersonen die Lehrpersonen ystematisierung der SchÃ¼lerinnen und SchÃ¼ler\n",
      "\n",
      "Temperature 0.05\n",
      "Die Grundlagen war dabei die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist ein gesellschaftlicher Arbeit ist ein gewisser Arbeit in der Schule und Schwierigkeiten ausgewissen die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist auch die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist auch die SchÃ¼lerinnen und SchÃ¼ler sehr gut gesehen. Das ist ein gesellschaftlicher Arbeit ist eine gewisse Aussage der Leh\n"
     ]
    }
   ],
   "source": [
    "ts = (1.0, 1.0, 0.5, 0.5, 0.1, 0.05)\n",
    "with tf.Session() as sess:\n",
    "    for t in ts:\n",
    "        print()\n",
    "        print(\"Temperature {}\".format(t))\n",
    "        print(generate(sess, seed, temperature=t, show=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Some observations:\n",
    "\n",
    "* For low temperatures, the system gets trapped in a kind of local minima.\n",
    "* At least it's political correct:'Schülerinnen und Schüler, 'Heilpädagogin oder dem Heilpädagogen'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
