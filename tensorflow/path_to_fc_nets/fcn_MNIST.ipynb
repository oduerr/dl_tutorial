{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron in TensorFlow (plain vanilla)\n",
    "\n",
    "In this script we build a small multilayer perceptron with two hidden layers having 500 and 50 neurons each for classifying the MNIST database of handwritten digits.\n",
    "\n",
    "For data-format see the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((4000, 1, 28, 28), (4000,), 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4000, 784)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import gzip\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(1)\n",
    "\n",
    "with gzip.open('../../lasagne/mnist_4000.pkl.gz', 'rb') as f:\n",
    "    (X,y) = pickle.load(f)\n",
    "PIXELS = len(X[0,0,0,:])\n",
    "\n",
    "print(X.shape, y.shape, PIXELS) #As read\n",
    "\n",
    "# We need to reshape for the MLP\n",
    "X = X.reshape([4000, 784])\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taken from http://stackoverflow.com/questions/29831489/numpy-1-hot-array\n",
    "def convertToOneHot(vector, num_classes=None):\n",
    "    result = np.zeros((len(vector), num_classes), dtype='int32')\n",
    "    result[np.arange(len(vector)), vector] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network\n",
    "Build a network with the following architecture.\n",
    "\n",
    "### Definition of the network (architecture)\n",
    "\n",
    "* An Input Layer with the following 2-dimensions: \n",
    "    * 0: Batch Size yet unkown hence `None`\n",
    "    * 1: 784 = 28*28 pixels\n",
    "* A hidden layer with 500 units\n",
    "* A second hidden layer with 50 units\n",
    "* An output layer with 10 units\n",
    "\n",
    "### Hints\n",
    "* The weights can be specified and intitialized as\n",
    "```{python}\n",
    "    w_1 = tf.Variable(tf.random_normal([784, 500]))\n",
    "```\n",
    "* Use ```tf.nn.sigmoid``` activations for the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(1)\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')\n",
    "\n",
    "# From Input to first hidden layer\n",
    "w_1 = tf.Variable(tf.random_normal([784, 500], stddev=0.1))\n",
    "b_1 = tf.Variable(tf.random_normal([500]))\n",
    "h_1_in = tf.add(tf.matmul(x, w_1), b_1)\n",
    "h_1_out = tf.nn.relu(h_1_in)\n",
    "\n",
    "# From first hidden layer to second hidden layer\n",
    "# <--- Your code here --->\n",
    "w_2 = tf.Variable(tf.random_normal([500, 50], stddev=0.1))\n",
    "b_2 = tf.Variable(tf.random_normal([50]))\n",
    "h_2_in = tf.add(tf.matmul(h_1_out, w_2), b_2)\n",
    "h_2_out = tf.nn.relu(h_2_in)\n",
    "# <--- End of your code here --->\n",
    "\n",
    "# From second hidden layer to output\n",
    "w_3 = tf.Variable(tf.random_normal([50, 10], stddev=0.1))\n",
    "b_3 = tf.Variable(tf.random_normal([10]))\n",
    "h_3_in = tf.add(tf.matmul(h_2_out, w_3), b_3)\n",
    "\n",
    "# Output is softmax\n",
    "out = tf.nn.softmax(h_3_in)\n",
    "init_op = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the graph and visualize it in tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.summary.FileWriter(\"/tmp/dumm/mlp_tensorflow_solution/\", tf.get_default_graph()).close() #<--- Where to store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing a forward pass of the untrained network\n",
    "Since we fixed the random seed, you should you should get a result like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.89549232e-01,   6.02805465e-02,   5.36485866e-04,\n",
       "          3.27582695e-02,   3.45717650e-04,   2.12644130e-01,\n",
       "          1.91141307e-01,   1.51388312e-03,   1.65578678e-01,\n",
       "          4.56517488e-02],\n",
       "       [  4.15045202e-01,   8.72126669e-02,   2.26489659e-02,\n",
       "          7.13404343e-02,   6.83235144e-03,   5.74614033e-02,\n",
       "          7.40540475e-02,   1.08420523e-02,   2.10118622e-01,\n",
       "          4.44443673e-02]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    res_val = sess.run(out, feed_dict={x:X[0:2]})\n",
    "res_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss training 3.54543757439 validation 4.35267066956\n",
      "50 loss training 0.20824238658 validation 0.429773360491\n",
      "100 loss training 0.0884831100702 validation 0.465079754591\n",
      "150 loss training 0.0224867779762 validation 0.452041685581\n",
      "200 loss training 0.0356599390507 validation 0.488810360432\n",
      "250 loss training 0.0114144384861 validation 0.497321069241\n",
      "300 loss training 0.00527211278677 validation 0.508672058582\n",
      "350 loss training 0.00781277753413 validation 0.529542922974\n"
     ]
    }
   ],
   "source": [
    "loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.log(out), reduction_indices=[1]))\n",
    "#train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "train_op = tf.train.AdagradOptimizer(0.1).minimize(loss)\n",
    "init_op = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(400):\n",
    "        idx = np.random.permutation(2400)[0:128] #Easy minibatch of size 64\n",
    "        loss_, _ = sess.run((loss, train_op,), feed_dict={x:X[idx], y_true:convertToOneHot(y[idx], 10)})\n",
    "        if (i % 50 == 0):\n",
    "            loss_v = sess.run(loss, feed_dict={x:X[2400:3000], y_true:convertToOneHot(y[2400:3000], 10)})\n",
    "            print(\"{} loss training {} validation {}\".format(i, loss_, loss_v))\n",
    "    # Get the results for the validation results (from 2400:3000)\n",
    "    # Your code here\n",
    "    res_val = sess.run((out), feed_dict={x:X[2400:3000]})\n",
    "    res_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89500000000000002"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and estimate the preformance on the validation set\n",
    "# Your code here\n",
    "np.sum(np.argmax(res_val, axis = 1) == y[2400:3000]) / 600.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
